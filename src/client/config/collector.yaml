# LogNarrator Collector Configuration
# LogNarrator collector configuration

# Sources define where to collect logs from
sources:
  - source_type: file
    name: system-logs
    include:
      - /var/log/syslog
      - /var/log/messages
    exclude_filename_pattern: '.*\.gz$'
    start_at: end

  # Uncomment to enable journald source (Linux only)
  # - source_type: journald
  #   name: journal
  #   units:
  #     - systemd
  #     - sshd

  # Uncomment to enable Docker container logs source
  # - source_type: docker
  #   name: docker-logs
  #   containers:
  #     - container1
  #     - container2
  #   all_containers: false

  # Uncomment to enable OpenTelemetry receiver
  # - source_type: otlp
  #   name: otlp-receiver
  #   port: 4318
  #   interface: "0.0.0.0"

# Processors transform and filter logs
processors:
  - processor_type: resource
    name: metadata
    attributes:
      - action: insert
        key: host.name
        value: ${HOSTNAME}
      - action: insert
        key: service.name
        value: "lognarrator-client"

  - processor_type: filter
    name: error-filter
    logs:
      include:
        match_type: regexp
        regexp:
          - '.*error.*'
          - '.*warning.*'
          - '.*critical.*'

  - processor_type: transform
    name: mask-sensitive
    transforms:
      - transform_type: mask
        field: message
        parameters:
          pattern: '(password|secret)=[^\s]*'
          replacement: "$1=*****"

  - processor_type: batch
    name: batcher
    timeout: 5
    send_batch_size: 100

# Exporters define where to send logs
exporters:
  - exporter_type: lognarrator
    name: cloud-export
    endpoint: "https://api.lognarrator.com/v1/logs"
    client_id: "YOUR_CLIENT_ID"
    key_path: "/app/config/private.key"

  - exporter_type: localcache
    name: local-cache
    directory: "/app/data/logs"
    max_size_mb: 500
# Collection pipeline configuration
collector:
  # Receivers define how logs are collected
  receivers:
    # File-based log collection
    filelog:
      include:
        - /var/log/*.log
        - /var/log/syslog
        - /var/log/messages
      start_at: end
      exclude_filename_pattern: ".*\.gz$"
      encoding: utf-8

    # System log collection
    journald:
      directory: /var/log/journal
      units:
        - systemd
        - sshd

    # Container log collection
    dockerlogs:
      endpoint: "unix:///var/run/docker.sock"
      timeout: 5s
      exclude_labels:
        - "lognarrator.exclude=true"

    # HTTP-based log collection
    otlp/http:
      endpoint: 0.0.0.0:4318

  # Processors transform and filter logs
  processors:
    # Add metadata to logs
    resource:
      attributes:
        - action: insert
          key: host.name
          value: ${HOSTNAME}
        - action: insert
          key: service.name
          value: "lognarrator-client"

    # Filter out noisy logs
    filter:
      logs:
        include:
          match_type: regexp
          regexp:
            - '^.*error.*$'
            - '^.*warning.*$'
            - '^.*critical.*$'
            - '^.*exception.*$'

    # Limit log volume
    batch:
      timeout: 1s
      send_batch_size: 1024

  # Pipeline definitions connect receivers, processors, and exporters
  pipelines:
    logs/system:
      receivers: [filelog, journald]
      processors: [resource, filter, batch]
      exporters: [lognarrator]

    logs/container:
      receivers: [dockerlogs]
      processors: [resource, batch]
      exporters: [lognarrator]

    logs/otlp:
      receivers: [otlp/http]
      processors: [resource]
      exporters: [lognarrator]

# Encryption configuration
encryption:
  enabled: true
  keyPath: /app/config/private.key
  keyRotationDays: 30
  algorithm: XChaCha20-Poly1305
  clientId: ${CLIENT_ID}
  compression: true
  bufferSizeMB: 100

# Cloud exporter configuration
exporter:
  endpoint: ${API_URL}/api/v1/logs
  timeoutSeconds: 30
  retryMaxCount: 5
  retryDelaySeconds: 10
  batchSize: 100
  maxQueueSize: 10000
  tlsCertPath: /app/config/ca.crt
  tlsVerify: true
  localCachePath: /app/data/cache
